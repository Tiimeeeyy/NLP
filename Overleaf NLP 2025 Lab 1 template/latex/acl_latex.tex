% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{NLP 2025 Lab 1 Report: Tokenization}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{First Author \\
  Affiliation / Address line 1 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  \texttt{email@domain} \\\And
  Third Author \\
  Affiliation / Address line 1 \\
  \texttt{email@domain} \\}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
DELETE (OR REPLACE) AFTER YOU READ. This is a template for the report of the NLP 2025 labs. It is adapted from the Association for Computational Linguistics (ACL) conference\footnote{\url{https://aclrollingreview.org/authors}}. Fill in your names in the authors list and provide your answers to the exercises listed in the accompanying notebook. The answer to each exercise should be in a separate section. For the coding exercises, provide code snipped and a short explanation. For the open questions, you can add figures, plots, tables, etc. Make sure to include a short discussion.

You need to submit a PDF of your report (use the templates provided in latex (preferred) or word and a copy of your notebook with the code. Make sure that all figures/results/plots are shown in your (execucted) notebook. While you may talk with others about this lab, we ask that you write your solutions with your group only. If you do discuss specific tasks with others please include their names in the appendix. Honor code applies to this lab. For more check Syllabus ยง7.2. It is mandatory to list and disclose any website (or other resource) you used (e.g. stackoverflow) as well as any genAI tools (e.g. chatGPT) used. Failure to disclose these is a violation of academic integrity. For more check Syllabus ยง7.3. THIS TEXT WILL BE SELF-DESTROYED AFTER YOU READ IT.
\end{abstract}

\section*{Uesful \LaTeX{} commands}
In this short section we will show you several commands that you can adapt when writing your answers. Feel free to remove this section before submitting your report.

To write a short in-line code snippet you can use the following command \verb|print('Hello World')|. For longer pieces of code use the following:
\begin{quote}
\begin{verbatim}
def foo():
    print('Hello World')
\end{verbatim}
\end{quote}

Here is the example of a table. Each table and figure should have a reference from text. You can set the label in the table and use \verb|\ref{tab:citations}| command to reference it. For example, Table~\ref{tab:citations} presents different ways to cite a bibliography. In the report, you can add references but it is not required.

\begin{table}
  \centering
  \begin{tabular}{lll}
    \hline
    \textbf{Output}           & \textbf{natbib command} \\
    \hline
    \citep{Gusfield:97}       & \verb|\citep|           \\
    \citet{Gusfield:97}       & \verb|\citet|           \\
    \hline
  \end{tabular}
  \caption{\label{citation-guide}
    Citation commands supported by the style file.
    The style is based on the natbib package and supports all natbib citation commands.
  }
  \label{tab:citations}
\end{table}

Figures can be added by first uploading the image file to overleaf and then using the following command (and reference it using Figure~\ref{fig:zipf}):
\begin{figure}[t]

  \caption{This is a caption of the figure.}
  \label{fig:zipf}
\end{figure}

\section{Exercise 1: Questions about the datasets}

Your answers here.

\subsection{What is the size of the training, test and validation datasets?}
The training set contains 45000 rows, the testing dataset contains 50000 rows, and the testing dataset contains 5000 rows. 

\subsection{What are the top 5 most frequent emojis in the validation dataset?}
\begin{enumerate}
	\item Heart
	\item Heart eyes
	\item Laughing 
	\item Stars 
	\item Fire 
\end{enumerate}
 \subsection{Compare the distributions of labels (emojis) between training and validation datasets.}
\begin{figure}[h]
	\includegraphics[width=\linewidth]{graph1.png}
	\caption{The distribution of labels between training and validation datasets}
\end{figure}
From the figure we can see, that the distribution of emojis is not significantly different in any of the two datasets
\subsection{How many examples with the "fire" emoji are in the training dataset?}
To solve this exercise, we just need to query the dataset. From the huggingface website, we can see, that the label of the fire emoji is 4. Therefore we just need to call
\begin{verbatim}
	.query("label == 4")
\end{verbatim}
on our training dataset. When we do this, we can see that we have 2146 occurences of the fire emoji in the training dataset.

\subsection{What is the average length (in characters) of the tweets in the training dataset?}
For this, we just need to take the "text\_length" column of the training dataset, and then call the inbuilt mean function of pandas on it. When running the code, we get 71.01691111 average tweet length.

\section{Exercise 2: Write the text cleaning function}

\section{Exercise 3: Build the vocabulary}

\section{Exercise 4: Frequency of pairs of words}
\subsection{Most and Least common pairs}
\begin{verbatim}
	bigram_counter = Counter()
	for example in tweet_ds['train']:
	words = example["clean"].split()
	bigrams = zip(words[:-1], words[1:])
	bigram_counter.update(bigrams)
	print("The most common bigrams: ")
	print(bigram_counter.most_common(10))
	print("\nThe least common bigrams:")
	print(bigram_counter.most_common()[-10:])
\end{verbatim}
Here we just initialize a Counter object from the Python collections library. We then iterate over the training dataset, split the string on whitespace, then use the zip iterator, to get our bigrams. We then push our bigrams into the counter object. From there we can Poll the  most and least common bigrams, as seen in the code. 

\subsection{How many pairs occur only once?}
To count single occurences, we need to iterate over our Counter object again, and then count the items in it. If the count of any item is equal to one, we add it to the sum, which is our output. When we calculate this, we get that we have 240574 bigrams that only occur once. 
\subsection{Distribution plot of the frequencies}
\begin{figure}[h]
	\includegraphics[width=\linewidth]{graph2.png}
	\caption{Distribution plot of the bigram frequencies in a log-log scale}
\end{figure}
\section{Exercise 5: Tokenize the dataset}

\section{Exercise 6: Questions about the tokenization}

\section{Exercise 7: Counting the characters}
Here we again make use of the Counter object. We iterate over our dataset, take the "clean" column, then we iterate over the characters in that column and increase the counter for each character we get. 
\begin{verbatim}
	 # First, we iterate over all examples in the dataset:
	for example in dataset:
	# We then get the sample text from the "clean"
	# column of the dataset:
	text = example['clean']
	# Then we iterate over the texts' characters and
	# count each character individually:
	for char in text:
	char_counter[char] += 1
\end{verbatim}

\section{Exercise 8: Calculate the frequency statistics of adjacent symbol pairs}

\section{Exercise 9: BPE algorithm}

\section{Exercise 10: Comparing tokenizers}

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only

\bibliography{custom}

\appendix

\section{Collaborators outside our group}



\section{Use of genAI}

Use of genAI tools (e.g. chatGPT), websites (e.g. stackoverflow): list websites where you found code (or other info) as well as include information on how you used genAI tools (e.g. prompts).  Failure to disclose use of genAI tools is violation of adademic integrity.

% This is an appendix.

\end{document}
